{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, TextVectorization\n",
    "from pathlib import Path\n",
    "from MetricsCallbackKeras import MetricsCallback\n",
    "import psycopg2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(database=\"mt_metrics\",\n",
    "                        host=\"localhost\",\n",
    "                        user=\"jonah\",\n",
    "                        password=\"getting started\",\n",
    "                        port=5432)\n",
    "conn.autocommit = True\n",
    "\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop\n",
    "# from keras import ops\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import data as tf_data\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow.data as tf_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Centralization for Better Training Performance\n",
    "Author: Rishit Dagli\n",
    "\n",
    "Description: Implement Gradient Centralization to improve training performance of DNNs.\n",
    "\n",
    "https://keras.io/examples/vision/gradient_centralization/\n",
    "\n",
    "First run is WITHOUT gradient centralization, second is WITH gradient centralization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MODEL_NAME\"] = \"Horses or Humans without Gradient Centralization\"\n",
    "os.environ[\"MODEL_TYPE\"] = \"RMSprop\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (300, 300, 3)\n",
      "Training images: 1027\n",
      "Test images: 256\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "input_shape = (300, 300, 3)\n",
    "dataset_name = \"horses_or_humans\"\n",
    "batch_size = 128\n",
    "AUTOTUNE = tf_data.AUTOTUNE\n",
    "\n",
    "(train_ds, test_ds), metadata = tfds.load(\n",
    "    name=dataset_name,\n",
    "    split=[tfds.Split.TRAIN, tfds.Split.TEST],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")\n",
    "\n",
    "print(f\"Image shape: {metadata.features['image'].shape}\")\n",
    "print(f\"Training images: {metadata.splits['train'].num_examples}\")\n",
    "print(f\"Test images: {metadata.splits['test'].num_examples}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale = layers.Rescaling(1.0 / 255)\n",
    "\n",
    "data_augmentation = [\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.3),\n",
    "    layers.RandomZoom(0.2),\n",
    "]\n",
    "\n",
    "\n",
    "# Helper to apply augmentation\n",
    "def apply_aug(x):\n",
    "    for aug in data_augmentation:\n",
    "        x = aug(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def prepare(ds, shuffle=False, augment=False):\n",
    "    # Rescale dataset\n",
    "    ds = ds.map(lambda x, y: (rescale(x), y), num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1024)\n",
    "\n",
    "    # Batch dataset\n",
    "    ds = ds.batch(batch_size)\n",
    "\n",
    "    # Use data augmentation only on the training set\n",
    "    if augment:\n",
    "        ds = ds.map(\n",
    "            lambda x, y: (apply_aug(x), y),\n",
    "            num_parallel_calls=AUTOTUNE,\n",
    "        )\n",
    "\n",
    "    # Use buffered prefecting\n",
    "    return ds.prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = prepare(train_ds, shuffle=True, augment=True)\n",
    "test_ds = prepare(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.Conv2D(16, (3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(2, 2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.GCRMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.GCRMSprop`.\n"
     ]
    }
   ],
   "source": [
    "class GCRMSprop(RMSprop):\n",
    "    def get_gradients(self, loss, params):\n",
    "        # We here just provide a modified get_gradients() function since we are\n",
    "        # trying to just compute the centralized gradients.\n",
    "\n",
    "        grads = []\n",
    "        gradients = super().get_gradients()\n",
    "        for grad in gradients:\n",
    "            grad_len = len(grad.shape)\n",
    "            if grad_len > 1:\n",
    "                axis = list(range(grad_len - 1))\n",
    "                grad -= keras.keras.keras.keras.keras.keras.keras.keras.keras.ops.mean(grad, axis=axis, keep_dims=True)\n",
    "            grads.append(grad)\n",
    "\n",
    "        return grads\n",
    "\n",
    "\n",
    "optimizer = GCRMSprop(learning_rate=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time() - self.epoch_time_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 298, 298, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 149, 149, 16)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 147, 147, 32)      4640      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 147, 147, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 73, 73, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 71, 71, 64)        18496     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 71, 71, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 35, 35, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 33, 33, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 7, 7, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1606144   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1704097 (6.50 MB)\n",
      "Trainable params: 1704097 (6.50 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "time_callback_no_gc = TimeHistory()\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=RMSprop(learning_rate=1e-4),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "9/9 [==============================] - 16s 1s/step - loss: 0.7038 - accuracy: 0.4907\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 15s 1s/step - loss: 0.6784 - accuracy: 0.6008\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.6663 - accuracy: 0.6086\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.6623 - accuracy: 0.6514\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 15s 1s/step - loss: 0.6363 - accuracy: 0.6758\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.6135 - accuracy: 0.6699\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.6038 - accuracy: 0.6943\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.5816 - accuracy: 0.7361\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.5336 - accuracy: 0.7868\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.5415 - accuracy: 0.7575\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.5723 - accuracy: 0.7546\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.4784 - accuracy: 0.7838\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.4679 - accuracy: 0.7945\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 15s 1s/step - loss: 0.4439 - accuracy: 0.8130\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 16s 2s/step - loss: 0.4589 - accuracy: 0.7975\n",
      "Epoch 1/15\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.4214 - accuracy: 0.8228\n",
      "Epoch 2/15\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.3937 - accuracy: 0.8384\n",
      "Epoch 3/15\n",
      "9/9 [==============================] - 15s 1s/step - loss: 0.4757 - accuracy: 0.7731\n",
      "Epoch 4/15\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.4400 - accuracy: 0.7965\n",
      "Epoch 5/15\n",
      "9/9 [==============================] - 15s 1s/step - loss: 0.3919 - accuracy: 0.8267\n",
      "Epoch 6/15\n",
      "9/9 [==============================] - 15s 1s/step - loss: 0.3957 - accuracy: 0.8306\n",
      "Epoch 7/15\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.3984 - accuracy: 0.8228\n",
      "Epoch 8/15\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.3651 - accuracy: 0.8500\n",
      "Epoch 9/15\n",
      "9/9 [==============================] - 15s 1s/step - loss: 0.3729 - accuracy: 0.8354\n",
      "Epoch 10/15\n",
      "9/9 [==============================] - 16s 1s/step - loss: 0.3816 - accuracy: 0.8286\n",
      "Epoch 11/15\n",
      "9/9 [==============================] - 15s 1s/step - loss: 0.3472 - accuracy: 0.8491\n",
      "Epoch 12/15\n",
      "9/9 [==============================] - 15s 1s/step - loss: 0.3437 - accuracy: 0.8471\n",
      "Epoch 13/15\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.3392 - accuracy: 0.8588\n",
      "Epoch 14/15\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.3295 - accuracy: 0.8578\n",
      "Epoch 15/15\n",
      "9/9 [==============================] - 15s 1s/step - loss: 0.3420 - accuracy: 0.8413\n"
     ]
    }
   ],
   "source": [
    "for num_epochs in [5, 10, 15]:\n",
    "    model.fit(\n",
    "        train_ds, epochs=num_epochs, verbose=1, callbacks=[time_callback_no_gc, MetricsCallback(cursor)]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MODEL_NAME\"] = \"Horses or Humans with Gradient Centralization\"\n",
    "os.environ[\"MODEL_TYPE\"] = \"Gradient Centralization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 298, 298, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 149, 149, 16)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 147, 147, 32)      4640      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 147, 147, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 73, 73, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 71, 71, 64)        18496     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 71, 71, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 35, 35, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 33, 33, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 7, 7, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3136)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1606144   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1704097 (6.50 MB)\n",
      "Trainable params: 1704097 (6.50 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "9/9 [==============================] - 15s 1s/step - loss: 0.3848 - accuracy: 0.8374\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 15s 1s/step - loss: 0.3345 - accuracy: 0.8608\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.3113 - accuracy: 0.8724\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.3424 - accuracy: 0.8578\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.3173 - accuracy: 0.8656\n",
      "Epoch 1/10\n",
      "9/9 [==============================] - 15s 1s/step - loss: 0.3180 - accuracy: 0.8695\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.3023 - accuracy: 0.8715\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.3186 - accuracy: 0.8754\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.2923 - accuracy: 0.8685\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.3163 - accuracy: 0.8695\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 15s 1s/step - loss: 0.2839 - accuracy: 0.8773\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.2928 - accuracy: 0.8909\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 15s 1s/step - loss: 0.2947 - accuracy: 0.8793\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 15s 1s/step - loss: 0.2905 - accuracy: 0.8793\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 15s 1s/step - loss: 0.2589 - accuracy: 0.8919\n",
      "Epoch 1/15\n",
      "9/9 [==============================] - 15s 1s/step - loss: 0.3636 - accuracy: 0.8763\n",
      "Epoch 2/15\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.2557 - accuracy: 0.8870\n",
      "Epoch 3/15\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.2837 - accuracy: 0.8890\n",
      "Epoch 4/15\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.3283 - accuracy: 0.8647\n",
      "Epoch 5/15\n",
      "9/9 [==============================] - 15s 1s/step - loss: 0.2619 - accuracy: 0.8939\n",
      "Epoch 6/15\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.2751 - accuracy: 0.8783\n",
      "Epoch 7/15\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.2716 - accuracy: 0.8822\n",
      "Epoch 8/15\n",
      "9/9 [==============================] - 15s 1s/step - loss: 0.2671 - accuracy: 0.8890\n",
      "Epoch 9/15\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.2497 - accuracy: 0.8968\n",
      "Epoch 10/15\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.2868 - accuracy: 0.8929\n",
      "Epoch 11/15\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.2475 - accuracy: 0.8978\n",
      "Epoch 12/15\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.2577 - accuracy: 0.8909\n",
      "Epoch 13/15\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.2654 - accuracy: 0.8968\n",
      "Epoch 14/15\n",
      "9/9 [==============================] - 14s 1s/step - loss: 0.2183 - accuracy: 0.9114\n",
      "Epoch 15/15\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.2405 - accuracy: 0.8987\n"
     ]
    }
   ],
   "source": [
    "time_callback_gc = TimeHistory()\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "for num_epochs in [5, 10, 15]:\n",
    "    history_gc = model.fit(train_ds, epochs=num_epochs, verbose=1, callbacks=[time_callback_gc, MetricsCallback(cursor)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple MNIST convnet\n",
    "\n",
    "Author: fchollet\n",
    "\n",
    "Description: A simple convnet that achieves ~99% test accuracy on MNIST.\n",
    "\n",
    "https://keras.io/examples/vision/mnist_convnet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MODEL_NAME\"] = \"Simple MNIST Convnet\"\n",
    "os.environ[\"MODEL_TYPE\"] = \"Categorical Crossentropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# Load the data and split it between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 13, 13, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34826 (136.04 KB)\n",
      "Trainable params: 34826 (136.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.3624 - accuracy: 0.8908 - val_loss: 0.0791 - val_accuracy: 0.9798\n",
      "Epoch 2/10\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.1083 - accuracy: 0.9670 - val_loss: 0.0538 - val_accuracy: 0.9863\n",
      "Epoch 3/10\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0813 - accuracy: 0.9754 - val_loss: 0.0491 - val_accuracy: 0.9865\n",
      "Epoch 4/10\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0685 - accuracy: 0.9788 - val_loss: 0.0405 - val_accuracy: 0.9893\n",
      "Epoch 5/10\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0600 - accuracy: 0.9806 - val_loss: 0.0396 - val_accuracy: 0.9883\n",
      "Epoch 6/10\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0552 - accuracy: 0.9831 - val_loss: 0.0354 - val_accuracy: 0.9918\n",
      "Epoch 7/10\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0507 - accuracy: 0.9841 - val_loss: 0.0343 - val_accuracy: 0.9908\n",
      "Epoch 8/10\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0454 - accuracy: 0.9860 - val_loss: 0.0336 - val_accuracy: 0.9917\n",
      "Epoch 9/10\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0432 - accuracy: 0.9858 - val_loss: 0.0327 - val_accuracy: 0.9918\n",
      "Epoch 10/10\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0409 - accuracy: 0.9877 - val_loss: 0.0314 - val_accuracy: 0.9917\n",
      "Epoch 1/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0390 - accuracy: 0.9873 - val_loss: 0.0320 - val_accuracy: 0.9920\n",
      "Epoch 2/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0376 - accuracy: 0.9876 - val_loss: 0.0271 - val_accuracy: 0.9925\n",
      "Epoch 3/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0352 - accuracy: 0.9885 - val_loss: 0.0295 - val_accuracy: 0.9923\n",
      "Epoch 4/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0325 - accuracy: 0.9896 - val_loss: 0.0278 - val_accuracy: 0.9923\n",
      "Epoch 5/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0325 - accuracy: 0.9892 - val_loss: 0.0268 - val_accuracy: 0.9927\n",
      "Epoch 6/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0316 - accuracy: 0.9898 - val_loss: 0.0295 - val_accuracy: 0.9913\n",
      "Epoch 7/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0300 - accuracy: 0.9901 - val_loss: 0.0263 - val_accuracy: 0.9932\n",
      "Epoch 8/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0291 - accuracy: 0.9903 - val_loss: 0.0292 - val_accuracy: 0.9935\n",
      "Epoch 9/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0280 - accuracy: 0.9906 - val_loss: 0.0284 - val_accuracy: 0.9925\n",
      "Epoch 10/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0271 - accuracy: 0.9909 - val_loss: 0.0281 - val_accuracy: 0.9920\n",
      "Epoch 11/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0267 - accuracy: 0.9910 - val_loss: 0.0273 - val_accuracy: 0.9927\n",
      "Epoch 12/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0255 - accuracy: 0.9913 - val_loss: 0.0282 - val_accuracy: 0.9927\n",
      "Epoch 13/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 0.0266 - val_accuracy: 0.9935\n",
      "Epoch 14/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.0275 - val_accuracy: 0.9927\n",
      "Epoch 15/15\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0231 - accuracy: 0.9922 - val_loss: 0.0293 - val_accuracy: 0.9930\n",
      "Epoch 1/20\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.0273 - val_accuracy: 0.9928\n",
      "Epoch 2/20\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0226 - accuracy: 0.9924 - val_loss: 0.0274 - val_accuracy: 0.9940\n",
      "Epoch 3/20\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0230 - accuracy: 0.9927 - val_loss: 0.0284 - val_accuracy: 0.9925\n",
      "Epoch 4/20\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.0291 - val_accuracy: 0.9932\n",
      "Epoch 5/20\n",
      "422/422 [==============================] - 7s 16ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.0285 - val_accuracy: 0.9932\n",
      "Epoch 6/20\n",
      "422/422 [==============================] - 7s 16ms/step - loss: 0.0194 - accuracy: 0.9936 - val_loss: 0.0298 - val_accuracy: 0.9927\n",
      "Epoch 7/20\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0191 - accuracy: 0.9933 - val_loss: 0.0311 - val_accuracy: 0.9923\n",
      "Epoch 8/20\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0194 - accuracy: 0.9931 - val_loss: 0.0269 - val_accuracy: 0.9942\n",
      "Epoch 9/20\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0186 - accuracy: 0.9936 - val_loss: 0.0299 - val_accuracy: 0.9937\n",
      "Epoch 10/20\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0190 - accuracy: 0.9936 - val_loss: 0.0308 - val_accuracy: 0.9922\n",
      "Epoch 11/20\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0185 - accuracy: 0.9938 - val_loss: 0.0304 - val_accuracy: 0.9932\n",
      "Epoch 12/20\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 0.0312 - val_accuracy: 0.9928\n",
      "Epoch 13/20\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0185 - accuracy: 0.9938 - val_loss: 0.0275 - val_accuracy: 0.9942\n",
      "Epoch 14/20\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0183 - accuracy: 0.9940 - val_loss: 0.0279 - val_accuracy: 0.9938\n",
      "Epoch 15/20\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.0275 - val_accuracy: 0.9933\n",
      "Epoch 16/20\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0292 - val_accuracy: 0.9932\n",
      "Epoch 17/20\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0164 - accuracy: 0.9942 - val_loss: 0.0311 - val_accuracy: 0.9933\n",
      "Epoch 18/20\n",
      "422/422 [==============================] - 6s 15ms/step - loss: 0.0165 - accuracy: 0.9944 - val_loss: 0.0300 - val_accuracy: 0.9932\n",
      "Epoch 19/20\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0166 - accuracy: 0.9943 - val_loss: 0.0324 - val_accuracy: 0.9930\n",
      "Epoch 20/20\n",
      "422/422 [==============================] - 6s 14ms/step - loss: 0.0169 - accuracy: 0.9943 - val_loss: 0.0281 - val_accuracy: 0.9932\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "for num_epochs in [10, 15, 20]:\n",
    "    model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs, validation_split=0.1, callbacks=[MetricsCallback(cursor)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text classification from scratch\n",
    "\n",
    "Authors: Mark Omernick, Francois Chollet\n",
    "\n",
    "Description: Text sentiment classification starting from raw text files.\n",
    "\n",
    "https://keras.io/examples/nlp/text_classification_from_scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MODEL_NAME\"] = \"Text classification from scratch\"\n",
    "os.environ[\"MODEL_TYPE\"] = \"Binary Crossentropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 80.2M  100 80.2M    0     0  3764k      0  0:00:21  0:00:21 --:--:-- 3919k00:01  0:00:43 1862kM    0     0  3705k      0  0:00:22  0:00:16  0:00:06 3597k 3758k\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xf aclImdb_v1.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r aclImdb/train/unsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Number of batches in raw_train_ds: 625\n",
      "Number of batches in raw_val_ds: 157\n",
      "Number of batches in raw_test_ds: 782\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "raw_train_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    ")\n",
    "raw_val_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\",\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    ")\n",
    "raw_test_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/test\", batch_size=batch_size\n",
    ")\n",
    "\n",
    "print(f\"Number of batches in raw_train_ds: {raw_train_ds.cardinality()}\")\n",
    "print(f\"Number of batches in raw_val_ds: {raw_val_ds.cardinality()}\")\n",
    "print(f\"Number of batches in raw_test_ds: {raw_test_ds.cardinality()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'I\\'ve seen tons of science fiction from the 70s; some horrendously bad, and others thought provoking and truly frightening. Soylent Green fits into the latter category. Yes, at times it\\'s a little campy, and yes, the furniture is good for a giggle or two, but some of the film seems awfully prescient. Here we have a film, 9 years before Blade Runner, that dares to imagine the future as somthing dark, scary, and nihilistic. Both Charlton Heston and Edward G. Robinson fare far better in this than The Ten Commandments, and Robinson\\'s assisted-suicide scene is creepily prescient of Kevorkian and his ilk. Some of the attitudes are dated (can you imagine a filmmaker getting away with the \"women as furniture\" concept in our oh-so-politically-correct-90s?), but it\\'s rare to find a film from the Me Decade that actually can make you think. This is one I\\'d love to see on the big screen, because even in a widescreen presentation, I don\\'t think the overall scope of this film would receive its due. Check it out.'\n",
      "1\n",
      "b'First than anything, I\\'m not going to praise I\\xc3\\xb1arritu\\'s short film, even I\\'m Mexican and proud of his success in mainstream Hollywood.<br /><br />In another hand, I see most of the reviews focuses on their favorite (and not so) short films; but we are forgetting that there is a subtle bottom line that circles the whole compilation, and maybe it will not be so pleasant for American people. (Even if that was not the main purpose of the producers) <br /><br />What i\\'m talking about is that most of the short films does not show the suffering that WASP people went through because the terrorist attack on September 11th, but the suffering of the Other people.<br /><br />Do you need proofs about what i\\'m saying? Look, in the Bosnia short film, the message is: \"You cry because of the people who died in the Towers, but we (The Others = East Europeans) are crying long ago for the crimes committed against our women and nobody pay attention to us like the whole world has done to you\".<br /><br />Even though the Burkina Fasso story is more in comedy, there is a the same thought: \"You are angry because Osama Bin Laden punched you in an evil way, but we (The Others = Africans) should be more angry, because our people is dying of hunger, poverty and AIDS long time ago, and nobody pay attention to us like the whole world has done to you\".<br /><br />Look now at the Sean Penn short: The fall of the Twin Towers makes happy to a lonely (and alienated) man. So the message is that the Power and the Greed (symbolized by the Towers) must fall for letting the people see the sun rise and the flowers blossom? It is remarkable that this terrible bottom line has been proposed by an American. There is so much irony in this short film that it is close to be subversive.<br /><br />Well, the Ken Loach (very know because his anti-capitalism ideology) is much more clearly and shameless in going straight to the point: \"You are angry because your country has been attacked by evil forces, but we (The Others = Latin Americans) suffered at a similar date something worst, and nobody remembers our grief as the whole world has done to you\".<br /><br />It is like if the creative of this project wanted to say to Americans: \"You see now, America? You are not the only that have become victim of the world violence, you are not alone in your pain and by the way, we (the Others = the Non Americans) have been suffering a lot more than you from long time ago; so, we are in solidarity with you in your pain... and by the way, we are sorry because you have had some taste of your own medicine\" Only the Mexican and the French short films showed some compassion and sympathy for American people; the others are like a slap on the face for the American State, that is not equal to American People.'\n",
      "1\n",
      "b'Blood Castle (aka Scream of the Demon Lover, Altar of Blood, Ivanna--the best, but least exploitation cinema-sounding title, and so on) is a very traditional Gothic Romance film. That means that it has big, creepy castles, a headstrong young woman, a mysterious older man, hints of horror and the supernatural, and romance elements in the contemporary sense of that genre term. It also means that it is very deliberately paced, and that the film will work best for horror mavens who are big fans of understatement. If you love films like Robert Wise\\'s The Haunting (1963), but you also have a taste for late 1960s/early 1970s Spanish and Italian horror, you may love Blood Castle, as well.<br /><br />Baron Janos Dalmar (Carlos Quiney) lives in a large castle on the outskirts of a traditional, unspecified European village. The locals fear him because legend has it that whenever he beds a woman, she soon after ends up dead--the consensus is that he sets his ferocious dogs on them. This is quite a problem because the Baron has a very healthy appetite for women. At the beginning of the film, yet another woman has turned up dead and mutilated.<br /><br />Meanwhile, Dr. Ivanna Rakowsky (Erna Sch\\xc3\\xbcrer) has appeared in the center of the village, asking to be taken to Baron Dalmar\\'s castle. She\\'s an out-of-towner who has been hired by the Baron for her expertise in chemistry. Of course, no one wants to go near the castle. Finally, Ivanna finds a shady individual (who becomes even shadier) to take her. Once there, an odd woman who lives in the castle, Olga (Cristiana Galloni), rejects Ivanna and says that she shouldn\\'t be there since she\\'s a woman. Baron Dalmar vacillates over whether she should stay. She ends up staying, but somewhat reluctantly. The Baron has hired her to try to reverse the effects of severe burns, which the Baron\\'s brother, Igor, is suffering from.<br /><br />Unfortunately, the Baron\\'s brother appears to be just a lump of decomposing flesh in a vat of bizarre, blackish liquid. And furthermore, Ivanna is having bizarre, hallucinatory dreams. Just what is going on at the castle? Is the Baron responsible for the crimes? Is he insane? <br /><br />I wanted to like Blood Castle more than I did. As I mentioned, the film is very deliberate in its pacing, and most of it is very understated. I can go either way on material like that. I don\\'t care for The Haunting (yes, I\\'m in a very small minority there), but I\\'m a big fan of 1960s and 1970s European horror. One of my favorite directors is Mario Bava. I also love Dario Argento\\'s work from that period. But occasionally, Blood Castle moved a bit too slow for me at times. There are large chunks that amount to scenes of not very exciting talking alternated with scenes of Ivanna slowly walking the corridors of the castle.<br /><br />But the atmosphere of the film is decent. Director Jos\\xc3\\xa9 Luis Merino managed more than passable sets and locations, and they\\'re shot fairly well by Emanuele Di Cola. However, Blood Castle feels relatively low budget, and this is a Roger Corman-produced film, after all (which usually means a low-budget, though often surprisingly high quality \"quickie\"). So while there is a hint of the lushness of Bava\\'s colors and complex set decoration, everything is much more minimalist. Of course, it doesn\\'t help that the Retromedia print I watched looks like a 30-year old photograph that\\'s been left out in the sun too long. It appears \"washed out\", with compromised contrast.<br /><br />Still, Merino and Di Cola occasionally set up fantastic visuals. For example, a scene of Ivanna walking in a darkened hallway that\\'s shot from an exaggerated angle, and where an important plot element is revealed through shadows on a wall only. There are also a couple Ingmar Bergmanesque shots, where actors are exquisitely blocked to imply complex relationships, besides just being visually attractive and pulling your eye deep into the frame.<br /><br />The performances are fairly good, and the women--especially Sch\\xc3\\xbcrer--are very attractive. Merino exploits this fact by incorporating a decent amount of nudity. Sch\\xc3\\xbcrer went on to do a number of films that were as much soft corn porn as they were other genres, with English titles such as Sex Life in a Woman\\'s Prison (1974), Naked and Lustful (1974), Strip Nude for Your Killer (1975) and Erotic Exploits of a Sexy Seducer (1977). Blood Castle is much tamer, but in addition to the nudity, there are still mild scenes suggesting rape and bondage, and of course the scenes mixing sex and death.<br /><br />The primary attraction here, though, is probably the story, which is much a slow-burning romance as anything else. The horror elements, the mystery elements, and a somewhat unexpected twist near the end are bonuses, but in the end, Blood Castle is a love story, about a couple overcoming various difficulties and antagonisms (often with physical threats or harms) to be together.'\n",
      "1\n",
      "b\"I was talked into watching this movie by a friend who blubbered on about what a cute story this was.<br /><br />Yuck.<br /><br />I want my two hours back, as I could have done SO many more productive things with my time...like, for instance, twiddling my thumbs. I see nothing redeeming about this film at all, save for the eye-candy aspect of it...<br /><br />3/10 (and that's being generous)\"\n",
      "0\n",
      "b\"Michelle Rodriguez is the defining actress who could be the charging force for other actresses to look out for. She has the audacity to place herself in a rarely seen tough-girl role very early in her career (and pull it off), which is a feat that should be recognized. Although her later films pigeonhole her to that same role, this film was made for her ruggedness.<br /><br />Her character is a romanticized student/fighter/lover, struggling to overcome her disenchanted existence in the projects, which is a little overdone in film...but not by a girl. That aspect of this film isn't very original, but the story goes in depth when the heated relationships that this girl has to deal with come to a boil and her primal rage takes over.<br /><br />I haven't seen an actress take such an aggressive stance in movie-making yet, and I'm glad that she's getting that original twist out there in Hollywood. This film got a 7 from me because of the average story of ghetto youth, but it has such a great actress portraying a rarely-seen role in a minimal budget movie. Great work.\"\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "    for i in range(5):\n",
    "        print(text_batch.numpy()[i])\n",
    "        print(label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "# Having looked at our data above, we see that the raw text contains HTML break\n",
    "# tags of the form '<br />'. These tags will not be removed by the default\n",
    "# standardizer (which doesn't strip HTML). Because of this, we will need to\n",
    "# create a custom standardization function.\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
    "    return tf.strings.regex_replace(\n",
    "        stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Model constants.\n",
    "max_features = 20000\n",
    "embedding_dim = 128\n",
    "sequence_length = 500\n",
    "\n",
    "# Now that we have our custom standardization, we can instantiate our text\n",
    "# vectorization layer. We are using this layer to normalize, split, and map\n",
    "# strings to integers, so we set our 'output_mode' to 'int'.\n",
    "# Note that we're using the default split function,\n",
    "# and the custom standardization defined above.\n",
    "# We also set an explicit maximum sequence length, since the CNNs later in our\n",
    "# model won't support ragged sequences.\n",
    "vectorize_layer = keras.layers.TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=max_features,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "\n",
    "# Now that the vectorize_layer has been created, call `adapt` on a text-only\n",
    "# dataset to create the vocabulary. You don't have to batch, but for very large\n",
    "# datasets this means you're not keeping spare copies of the dataset in memory.\n",
    "\n",
    "# Let's make a text-only dataset (no labels):\n",
    "text_ds = raw_train_ds.map(lambda x, y: x)\n",
    "# Let's call `adapt`:\n",
    "vectorize_layer.adapt(text_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorize_layer(text), label\n",
    "\n",
    "\n",
    "# Vectorize the data.\n",
    "train_ds = raw_train_ds.map(vectorize_text)\n",
    "val_ds = raw_val_ds.map(vectorize_text)\n",
    "test_ds = raw_test_ds.map(vectorize_text)\n",
    "\n",
    "# Do async prefetching / buffering of the data for best performance on GPU.\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=10)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=10)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A integer input for vocab indices.\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "# Next, we add a layer to map those vocab indices into a space of dimensionality\n",
    "# 'embedding_dim'.\n",
    "x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "predictions = layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs, predictions)\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "625/625 [==============================] - 17s 26ms/step - loss: 0.5046 - accuracy: 0.7134 - val_loss: 0.3066 - val_accuracy: 0.8732\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.2249 - accuracy: 0.9129 - val_loss: 0.3137 - val_accuracy: 0.8762\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 17s 26ms/step - loss: 0.1089 - accuracy: 0.9609 - val_loss: 0.3975 - val_accuracy: 0.8726\n",
      "Epoch 1/6\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.0674 - accuracy: 0.9753 - val_loss: 0.4600 - val_accuracy: 0.8676\n",
      "Epoch 2/6\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.0419 - accuracy: 0.9860 - val_loss: 0.5145 - val_accuracy: 0.8696\n",
      "Epoch 3/6\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.0251 - accuracy: 0.9912 - val_loss: 0.6097 - val_accuracy: 0.8702\n",
      "Epoch 4/6\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.0235 - accuracy: 0.9914 - val_loss: 0.7092 - val_accuracy: 0.8628\n",
      "Epoch 5/6\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.9615 - val_accuracy: 0.8406\n",
      "Epoch 6/6\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.0187 - accuracy: 0.9927 - val_loss: 0.8535 - val_accuracy: 0.8590\n",
      "Epoch 1/9\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.0213 - accuracy: 0.9924 - val_loss: 0.8904 - val_accuracy: 0.8602\n",
      "Epoch 2/9\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.0140 - accuracy: 0.9948 - val_loss: 1.0173 - val_accuracy: 0.8544\n",
      "Epoch 3/9\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.0132 - accuracy: 0.9956 - val_loss: 0.9968 - val_accuracy: 0.8576\n",
      "Epoch 4/9\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.0126 - accuracy: 0.9959 - val_loss: 1.1658 - val_accuracy: 0.8538\n",
      "Epoch 5/9\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.8126 - val_accuracy: 0.8708\n",
      "Epoch 6/9\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.0079 - accuracy: 0.9971 - val_loss: 1.0784 - val_accuracy: 0.8650\n",
      "Epoch 7/9\n",
      "625/625 [==============================] - 15s 24ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.9451 - val_accuracy: 0.8646\n",
      "Epoch 8/9\n",
      "625/625 [==============================] - 16s 25ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 1.1268 - val_accuracy: 0.8678\n",
      "Epoch 9/9\n",
      "625/625 [==============================] - 15s 25ms/step - loss: 0.0067 - accuracy: 0.9977 - val_loss: 1.1206 - val_accuracy: 0.8698\n"
     ]
    }
   ],
   "source": [
    "# epochs = 3\n",
    "\n",
    "# Fit the model using the train and test datasets.\n",
    "\n",
    "for num_epochs in [3, 6, 9]:\n",
    "    model.fit(train_ds, validation_data=val_ds, epochs=num_epochs, callbacks=[MetricsCallback(cursor)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured data classification with FeatureSpace\n",
    "\n",
    "Author: fchollet\n",
    "\n",
    "Description: Classify tabular data in a few lines of code.\n",
    "\n",
    "https://keras.io/examples/structured_data/structured_data_classification_with_feature_space/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MODEL_NAME\"] = \"FeatureSpace Structured Data Classification\"\n",
    "os.environ[\"MODEL_TYPE\"] = \"Imbalanced Classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import FeatureSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n",
    "dataframe = pd.read_csv(file_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 242 samples for training and 61 for validation\n"
     ]
    }
   ],
   "source": [
    "val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\n",
    "train_dataframe = dataframe.drop(val_dataframe.index)\n",
    "\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"target\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'age': <tf.Tensor: shape=(), dtype=int64, numpy=64>, 'sex': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'cp': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'trestbps': <tf.Tensor: shape=(), dtype=int64, numpy=140>, 'chol': <tf.Tensor: shape=(), dtype=int64, numpy=335>, 'fbs': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'restecg': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'thalach': <tf.Tensor: shape=(), dtype=int64, numpy=158>, 'exang': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'oldpeak': <tf.Tensor: shape=(), dtype=float64, numpy=0.0>, 'slope': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'ca': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'thal': <tf.Tensor: shape=(), dtype=string, numpy=b'normal'>}\n",
      "Target: tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(32)\n",
    "val_ds = val_ds.batch(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_space = FeatureSpace(\n",
    "    features={\n",
    "        # Categorical features encoded as integers\n",
    "        \"sex\": \"integer_categorical\",\n",
    "        \"cp\": \"integer_categorical\",\n",
    "        \"fbs\": \"integer_categorical\",\n",
    "        \"restecg\": \"integer_categorical\",\n",
    "        \"exang\": \"integer_categorical\",\n",
    "        \"ca\": \"integer_categorical\",\n",
    "        # Categorical feature encoded as string\n",
    "        \"thal\": \"string_categorical\",\n",
    "        # Numerical features to discretize\n",
    "        \"age\": \"float_discretized\",\n",
    "        # Numerical features to normalize\n",
    "        \"trestbps\": \"float_normalized\",\n",
    "        \"chol\": \"float_normalized\",\n",
    "        \"thalach\": \"float_normalized\",\n",
    "        \"oldpeak\": \"float_normalized\",\n",
    "        \"slope\": \"float_normalized\",\n",
    "    },\n",
    "    # We create additional features by hashing\n",
    "    # value co-occurrences for the\n",
    "    # following groups of categorical features.\n",
    "    crosses=[(\"sex\", \"age\"), (\"thal\", \"ca\")],\n",
    "    # The hashing space for these co-occurrences\n",
    "    # wil be 32-dimensional.\n",
    "    crossing_dim=32,\n",
    "    # Our utility will one-hot encode all categorical\n",
    "    # features and concat all features into a single\n",
    "    # vector (one vector per sample).\n",
    "    output_mode=\"concat\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_space = FeatureSpace(\n",
    "    features={\n",
    "        # Categorical features encoded as integers\n",
    "        \"sex\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"cp\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"fbs\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"restecg\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"exang\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        \"ca\": FeatureSpace.integer_categorical(num_oov_indices=0),\n",
    "        # Categorical feature encoded as string\n",
    "        \"thal\": FeatureSpace.string_categorical(num_oov_indices=0),\n",
    "        # Numerical features to discretize\n",
    "        \"age\": FeatureSpace.float_discretized(num_bins=30),\n",
    "        # Numerical features to normalize\n",
    "        \"trestbps\": FeatureSpace.float_normalized(),\n",
    "        \"chol\": FeatureSpace.float_normalized(),\n",
    "        \"thalach\": FeatureSpace.float_normalized(),\n",
    "        \"oldpeak\": FeatureSpace.float_normalized(),\n",
    "        \"slope\": FeatureSpace.float_normalized(),\n",
    "    },\n",
    "    # Specify feature cross with a custom crossing dim.\n",
    "    crosses=[\n",
    "        FeatureSpace.cross(feature_names=(\"sex\", \"age\"), crossing_dim=64),\n",
    "        FeatureSpace.cross(\n",
    "            feature_names=(\"thal\", \"ca\"),\n",
    "            crossing_dim=16,\n",
    "        ),\n",
    "    ],\n",
    "    output_mode=\"concat\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_with_no_labels = train_ds.map(lambda x, _: x)\n",
    "feature_space.adapt(train_ds_with_no_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed_x.shape: (32, 138)\n",
      "preprocessed_x.dtype: <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "for x, _ in train_ds.take(1):\n",
    "    preprocessed_x = feature_space(x)\n",
    "    print(\"preprocessed_x.shape:\", preprocessed_x.shape)\n",
    "    print(\"preprocessed_x.dtype:\", preprocessed_x.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train_ds = train_ds.map(\n",
    "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "preprocessed_train_ds = preprocessed_train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "preprocessed_val_ds = val_ds.map(\n",
    "    lambda x, y: (feature_space(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "preprocessed_val_ds = preprocessed_val_ds.prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_inputs = feature_space.get_inputs()\n",
    "encoded_features = feature_space.get_encoded_features()\n",
    "\n",
    "x = keras.layers.Dense(32, activation=\"relu\")(encoded_features)\n",
    "x = keras.layers.Dropout(0.5)(x)\n",
    "predictions = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "training_model = keras.Model(inputs=encoded_features, outputs=predictions)\n",
    "training_model.compile(\n",
    "    optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "inference_model = keras.Model(inputs=dict_inputs, outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "8/8 - 0s - loss: 0.8196 - accuracy: 0.3802 - val_loss: 0.7108 - val_accuracy: 0.4918 - 427ms/epoch - 53ms/step\n",
      "Epoch 2/15\n",
      "8/8 - 0s - loss: 0.6957 - accuracy: 0.5537 - val_loss: 0.6522 - val_accuracy: 0.6557 - 149ms/epoch - 19ms/step\n",
      "Epoch 3/15\n",
      "8/8 - 0s - loss: 0.6741 - accuracy: 0.5826 - val_loss: 0.6043 - val_accuracy: 0.7377 - 149ms/epoch - 19ms/step\n",
      "Epoch 4/15\n",
      "8/8 - 0s - loss: 0.6203 - accuracy: 0.6488 - val_loss: 0.5655 - val_accuracy: 0.7705 - 148ms/epoch - 18ms/step\n",
      "Epoch 5/15\n",
      "8/8 - 0s - loss: 0.5775 - accuracy: 0.7066 - val_loss: 0.5331 - val_accuracy: 0.7541 - 146ms/epoch - 18ms/step\n",
      "Epoch 6/15\n",
      "8/8 - 0s - loss: 0.5569 - accuracy: 0.7479 - val_loss: 0.5075 - val_accuracy: 0.7377 - 153ms/epoch - 19ms/step\n",
      "Epoch 7/15\n",
      "8/8 - 0s - loss: 0.5273 - accuracy: 0.7397 - val_loss: 0.4836 - val_accuracy: 0.7377 - 151ms/epoch - 19ms/step\n",
      "Epoch 8/15\n",
      "8/8 - 0s - loss: 0.4978 - accuracy: 0.7479 - val_loss: 0.4655 - val_accuracy: 0.7541 - 148ms/epoch - 18ms/step\n",
      "Epoch 9/15\n",
      "8/8 - 0s - loss: 0.4713 - accuracy: 0.7603 - val_loss: 0.4485 - val_accuracy: 0.7213 - 159ms/epoch - 20ms/step\n",
      "Epoch 10/15\n",
      "8/8 - 0s - loss: 0.4479 - accuracy: 0.7893 - val_loss: 0.4344 - val_accuracy: 0.7377 - 149ms/epoch - 19ms/step\n",
      "Epoch 11/15\n",
      "8/8 - 0s - loss: 0.4234 - accuracy: 0.8017 - val_loss: 0.4219 - val_accuracy: 0.7541 - 150ms/epoch - 19ms/step\n",
      "Epoch 12/15\n",
      "8/8 - 0s - loss: 0.4088 - accuracy: 0.8223 - val_loss: 0.4122 - val_accuracy: 0.7705 - 153ms/epoch - 19ms/step\n",
      "Epoch 13/15\n",
      "8/8 - 0s - loss: 0.4004 - accuracy: 0.8140 - val_loss: 0.4039 - val_accuracy: 0.7705 - 145ms/epoch - 18ms/step\n",
      "Epoch 14/15\n",
      "8/8 - 0s - loss: 0.3746 - accuracy: 0.8306 - val_loss: 0.3970 - val_accuracy: 0.7705 - 148ms/epoch - 18ms/step\n",
      "Epoch 15/15\n",
      "8/8 - 0s - loss: 0.3740 - accuracy: 0.8512 - val_loss: 0.3914 - val_accuracy: 0.7705 - 153ms/epoch - 19ms/step\n",
      "Epoch 1/20\n",
      "8/8 - 0s - loss: 0.3391 - accuracy: 0.8430 - val_loss: 0.3867 - val_accuracy: 0.7705 - 154ms/epoch - 19ms/step\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 0.3414 - accuracy: 0.8512 - val_loss: 0.3830 - val_accuracy: 0.7705 - 152ms/epoch - 19ms/step\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 0.3341 - accuracy: 0.8554 - val_loss: 0.3812 - val_accuracy: 0.7869 - 151ms/epoch - 19ms/step\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 0.3292 - accuracy: 0.8719 - val_loss: 0.3793 - val_accuracy: 0.7869 - 148ms/epoch - 18ms/step\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 0.2962 - accuracy: 0.8926 - val_loss: 0.3782 - val_accuracy: 0.7869 - 149ms/epoch - 19ms/step\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 0.2940 - accuracy: 0.8595 - val_loss: 0.3780 - val_accuracy: 0.7869 - 148ms/epoch - 19ms/step\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 0.2729 - accuracy: 0.8967 - val_loss: 0.3795 - val_accuracy: 0.7869 - 150ms/epoch - 19ms/step\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 0.2849 - accuracy: 0.8843 - val_loss: 0.3809 - val_accuracy: 0.7869 - 154ms/epoch - 19ms/step\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 0.2916 - accuracy: 0.8636 - val_loss: 0.3811 - val_accuracy: 0.7869 - 156ms/epoch - 20ms/step\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 0.2757 - accuracy: 0.8926 - val_loss: 0.3839 - val_accuracy: 0.7869 - 163ms/epoch - 20ms/step\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.2697 - accuracy: 0.8884 - val_loss: 0.3863 - val_accuracy: 0.8033 - 152ms/epoch - 19ms/step\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.2823 - accuracy: 0.8678 - val_loss: 0.3888 - val_accuracy: 0.8033 - 164ms/epoch - 20ms/step\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.2594 - accuracy: 0.8967 - val_loss: 0.3905 - val_accuracy: 0.8033 - 147ms/epoch - 18ms/step\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.2553 - accuracy: 0.9050 - val_loss: 0.3913 - val_accuracy: 0.8033 - 149ms/epoch - 19ms/step\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.2656 - accuracy: 0.9091 - val_loss: 0.3918 - val_accuracy: 0.8033 - 152ms/epoch - 19ms/step\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.2564 - accuracy: 0.8843 - val_loss: 0.3923 - val_accuracy: 0.8033 - 145ms/epoch - 18ms/step\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.2481 - accuracy: 0.8884 - val_loss: 0.3937 - val_accuracy: 0.8033 - 152ms/epoch - 19ms/step\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.2810 - accuracy: 0.8719 - val_loss: 0.3941 - val_accuracy: 0.8033 - 152ms/epoch - 19ms/step\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.2327 - accuracy: 0.9050 - val_loss: 0.3954 - val_accuracy: 0.8033 - 153ms/epoch - 19ms/step\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.2292 - accuracy: 0.9215 - val_loss: 0.3967 - val_accuracy: 0.7869 - 152ms/epoch - 19ms/step\n",
      "Epoch 1/25\n",
      "8/8 - 0s - loss: 0.2450 - accuracy: 0.8926 - val_loss: 0.3976 - val_accuracy: 0.7869 - 153ms/epoch - 19ms/step\n",
      "Epoch 2/25\n",
      "8/8 - 0s - loss: 0.2563 - accuracy: 0.8926 - val_loss: 0.3981 - val_accuracy: 0.7869 - 166ms/epoch - 21ms/step\n",
      "Epoch 3/25\n",
      "8/8 - 0s - loss: 0.2299 - accuracy: 0.8967 - val_loss: 0.3999 - val_accuracy: 0.8033 - 157ms/epoch - 20ms/step\n",
      "Epoch 4/25\n",
      "8/8 - 0s - loss: 0.2136 - accuracy: 0.9174 - val_loss: 0.4034 - val_accuracy: 0.8033 - 156ms/epoch - 19ms/step\n",
      "Epoch 5/25\n",
      "8/8 - 0s - loss: 0.2385 - accuracy: 0.9008 - val_loss: 0.4058 - val_accuracy: 0.7869 - 157ms/epoch - 20ms/step\n",
      "Epoch 6/25\n",
      "8/8 - 0s - loss: 0.2326 - accuracy: 0.9132 - val_loss: 0.4079 - val_accuracy: 0.7869 - 149ms/epoch - 19ms/step\n",
      "Epoch 7/25\n",
      "8/8 - 0s - loss: 0.2229 - accuracy: 0.9050 - val_loss: 0.4090 - val_accuracy: 0.7869 - 152ms/epoch - 19ms/step\n",
      "Epoch 8/25\n",
      "8/8 - 0s - loss: 0.2473 - accuracy: 0.8926 - val_loss: 0.4099 - val_accuracy: 0.7869 - 151ms/epoch - 19ms/step\n",
      "Epoch 9/25\n",
      "8/8 - 0s - loss: 0.2228 - accuracy: 0.8843 - val_loss: 0.4111 - val_accuracy: 0.8033 - 157ms/epoch - 20ms/step\n",
      "Epoch 10/25\n",
      "8/8 - 0s - loss: 0.2228 - accuracy: 0.9008 - val_loss: 0.4125 - val_accuracy: 0.8033 - 148ms/epoch - 19ms/step\n",
      "Epoch 11/25\n",
      "8/8 - 0s - loss: 0.1996 - accuracy: 0.9174 - val_loss: 0.4149 - val_accuracy: 0.7869 - 153ms/epoch - 19ms/step\n",
      "Epoch 12/25\n",
      "8/8 - 0s - loss: 0.2110 - accuracy: 0.9215 - val_loss: 0.4168 - val_accuracy: 0.7869 - 152ms/epoch - 19ms/step\n",
      "Epoch 13/25\n",
      "8/8 - 0s - loss: 0.2117 - accuracy: 0.9174 - val_loss: 0.4181 - val_accuracy: 0.7869 - 151ms/epoch - 19ms/step\n",
      "Epoch 14/25\n",
      "8/8 - 0s - loss: 0.2184 - accuracy: 0.9132 - val_loss: 0.4187 - val_accuracy: 0.7869 - 154ms/epoch - 19ms/step\n",
      "Epoch 15/25\n",
      "8/8 - 0s - loss: 0.1848 - accuracy: 0.9339 - val_loss: 0.4191 - val_accuracy: 0.7869 - 159ms/epoch - 20ms/step\n",
      "Epoch 16/25\n",
      "8/8 - 0s - loss: 0.2010 - accuracy: 0.9215 - val_loss: 0.4215 - val_accuracy: 0.7869 - 150ms/epoch - 19ms/step\n",
      "Epoch 17/25\n",
      "8/8 - 0s - loss: 0.1897 - accuracy: 0.9298 - val_loss: 0.4234 - val_accuracy: 0.7869 - 149ms/epoch - 19ms/step\n",
      "Epoch 18/25\n",
      "8/8 - 0s - loss: 0.2010 - accuracy: 0.9215 - val_loss: 0.4257 - val_accuracy: 0.7869 - 153ms/epoch - 19ms/step\n",
      "Epoch 19/25\n",
      "8/8 - 0s - loss: 0.1956 - accuracy: 0.9215 - val_loss: 0.4282 - val_accuracy: 0.7869 - 151ms/epoch - 19ms/step\n",
      "Epoch 20/25\n",
      "8/8 - 0s - loss: 0.1843 - accuracy: 0.9380 - val_loss: 0.4296 - val_accuracy: 0.7869 - 147ms/epoch - 18ms/step\n",
      "Epoch 21/25\n",
      "8/8 - 0s - loss: 0.1848 - accuracy: 0.9174 - val_loss: 0.4311 - val_accuracy: 0.7869 - 148ms/epoch - 18ms/step\n",
      "Epoch 22/25\n",
      "8/8 - 0s - loss: 0.1748 - accuracy: 0.9215 - val_loss: 0.4324 - val_accuracy: 0.7869 - 152ms/epoch - 19ms/step\n",
      "Epoch 23/25\n",
      "8/8 - 0s - loss: 0.1877 - accuracy: 0.9174 - val_loss: 0.4347 - val_accuracy: 0.7869 - 148ms/epoch - 19ms/step\n",
      "Epoch 24/25\n",
      "8/8 - 0s - loss: 0.1819 - accuracy: 0.9174 - val_loss: 0.4373 - val_accuracy: 0.7869 - 154ms/epoch - 19ms/step\n",
      "Epoch 25/25\n",
      "8/8 - 0s - loss: 0.2069 - accuracy: 0.9174 - val_loss: 0.4379 - val_accuracy: 0.7869 - 159ms/epoch - 20ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for num_epochs in [15, 20, 25]:\n",
    "    training_model.fit(\n",
    "        preprocessed_train_ds,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=preprocessed_val_ds,\n",
    "        verbose=2,\n",
    "        callbacks=[MetricsCallback(cursor)]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
